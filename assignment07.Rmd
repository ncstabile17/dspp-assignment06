---
title: "Assignment 07"
author: "Nick Stabile"
date: "11/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(tidymodels)
```

## Exercise 01

### Creating the data set

```{r}

# use this url to download the data directly into R
df <- read_csv("https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv")

# clean names with janitor
sampled_df <- df %>% 
  janitor::clean_names() 

# create an inspection year variable
sampled_df <- sampled_df %>%
  mutate(inspection_date = mdy(inspection_date)) %>%
  mutate(inspection_year = year(inspection_date))

# get most-recent inspection
sampled_df <- sampled_df %>%
  group_by(camis) %>%
  filter(inspection_date == max(inspection_date)) %>%
  ungroup()

# subset the data
sampled_df <- sampled_df %>%
  select(camis, boro, zipcode, cuisine_description, inspection_date,
         action, violation_code, violation_description, grade,
         inspection_type, latitude, longitude, council_district,
         census_tract, inspection_year, critical_flag) %>%
  filter(complete.cases(.)) %>%
  filter(inspection_year >= 2017) %>%
  filter(grade %in% c("A", "B", "C")) 

# create the binary target variable
sampled_df <- sampled_df %>%
  mutate(grade = if_else(grade == "A", "A", "Not A")) %>%
  mutate(grade = as.factor(grade))

# create extra predictors
sampled_df <- sampled_df %>%
  group_by(boro, zipcode, cuisine_description, inspection_date,
           action, violation_code, violation_description, grade,
           inspection_type, latitude, longitude, council_district,
           census_tract, inspection_year)  %>%
  mutate(vermin = str_detect(violation_description, pattern = "mice|rats|vermin|roaches")) %>%
  summarize(violations = n(),
            vermin_types = sum(vermin),
            critical_flags = sum(critical_flag == "Y")) %>%
  ungroup()

# write the data
write_csv(sampled_df, "restaurant_grades.csv")


```

### 1. Estimate a model

```{r}
set.seed(20201020)

# create a split object
restaurant_grades_split <- initial_split(data = sampled_df, prop = 0.8)

# create the training and testing data
restaurant_grades_train <- training(x = restaurant_grades_split)
restaurant_grades_test <- testing(x = restaurant_grades_split)

# create recipe and downsample grades
predict_grade_cart_recipe <-
  recipe(formula = grade ~ ., data = restaurant_grades_train) %>%
  themis::step_downsample(grade)

# create model object
predict_grade_cart_mod <-
  decision_tree() %>%
  set_engine(engine = "rpart") %>%
  set_mode(mode = "classification")

# create a workflow with the recipe
predict_grade_cart_workflow <-
  workflow() %>%
  add_model(spec = predict_grade_cart_mod) %>%
  add_recipe(recipe = predict_grade_cart_recipe)

# fit the model using the workflow
predict_grade_cart_fit <- 
  predict_grade_cart_workflow %>% 
  fit(data = restaurant_grades_train)

```

### 2. Evaluate the model

```{r}

# use the model to get the predictions on the test data
grade_predictions <- bind_cols(
  restaurant_grades_test,
  predict(object = predict_grade_cart_fit, new_data = restaurant_grades_test)
)

# create a confusion matrix based on predictions of test data
grade_pred_conf_matrix <- table(grade_predictions$.pred_class, grade_predictions$grade)

grade_pred_conf_matrix

# Calculate precision and recall/sensitivity "by hand"
grade_pred_precision <- grade_pred_conf_matrix[1]/(grade_pred_conf_matrix[1] + grade_pred_conf_matrix[3])
grade_pred_precision

grade_pred_recall <- grade_pred_conf_matrix[1]/(grade_pred_conf_matrix[1] + grade_pred_conf_matrix[2])
grade_pred_recall

# Calculate precision and recall/sensitivity with tidymodels
precision(data = grade_predictions, truth = grade, estimate = .pred_class)

recall(data = grade_predictions, truth = grade, estimate = .pred_class)

```
c. The precision and recall calculated "by hand" match the values for precision and recall calculated using the tidymodels functions.

d. The model is very precise, with over 99% precision, meaning that it's almost almost correct when it predicts a restaurant will have an A grade. The model does somewhat worse on recall, with around 81% sensitivity, meaning that when the grade should be an A, there is about a 20% chance the model will predict Not A. In this sense it is a somewhat conservative model: it does not predict an A grade when it shouldn't (false positive), but it occasionally fails to predict A when it should have (false negative). This is probably a good thing for restaurant patrons since it is overly protective of their health, but would harm the marginal restaurant owner who should be receiving an A grade, but is not.