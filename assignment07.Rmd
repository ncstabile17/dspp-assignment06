---
title: "Assignment 07"
author: "Nick Stabile"
date: "11/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(tidymodels)
library(vip)
```

## Exercise 01

### Creating the data set

```{r}

# use this url to download the data directly into R
df <- read_csv("https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv")

# clean names with janitor
sampled_df <- df %>% 
  janitor::clean_names() 

# create an inspection year variable
sampled_df <- sampled_df %>%
  mutate(inspection_date = mdy(inspection_date)) %>%
  mutate(inspection_year = year(inspection_date))

# get most-recent inspection
sampled_df <- sampled_df %>%
  group_by(camis) %>%
  filter(inspection_date == max(inspection_date)) %>%
  ungroup()

# subset the data
sampled_df <- sampled_df %>%
  select(camis, boro, zipcode, cuisine_description, inspection_date,
         action, violation_code, violation_description, grade,
         inspection_type, latitude, longitude, council_district,
         census_tract, inspection_year, critical_flag) %>%
  filter(complete.cases(.)) %>%
  filter(inspection_year >= 2017) %>%
  filter(grade %in% c("A", "B", "C")) 

# create the binary target variable
sampled_df <- sampled_df %>%
  mutate(grade = if_else(grade == "A", "A", "Not A")) %>%
  mutate(grade = as.factor(grade))

# create extra predictors
sampled_df <- sampled_df %>%
  group_by(boro, zipcode, cuisine_description, inspection_date,
           action, violation_code, violation_description, grade,
           inspection_type, latitude, longitude, council_district,
           census_tract, inspection_year)  %>%
  mutate(vermin = str_detect(violation_description, pattern = "mice|rats|vermin|roaches")) %>%
  summarize(violations = n(),
            vermin_types = sum(vermin),
            critical_flags = sum(critical_flag == "Y")) %>%
  ungroup()

# write the data
write_csv(sampled_df, "restaurant_grades.csv")


```

### 1. Estimate a model

```{r}
set.seed(20201020)

# create a split object
restaurant_grades_split <- initial_split(data = sampled_df, prop = 0.8)

# create the training and testing data
restaurant_grades_train <- training(x = restaurant_grades_split)
restaurant_grades_test <- testing(x = restaurant_grades_split)

# create recipe and downsample grades
predict_grade_cart_recipe <-
  recipe(formula = grade ~ ., data = restaurant_grades_train) %>%
  themis::step_downsample(grade)

# create model object
predict_grade_cart_mod <-
  decision_tree() %>%
  set_engine(engine = "rpart") %>%
  set_mode(mode = "classification")

# create a workflow with the recipe
predict_grade_cart_workflow <-
  workflow() %>%
  add_model(spec = predict_grade_cart_mod) %>%
  add_recipe(recipe = predict_grade_cart_recipe)

# fit the model using the workflow
predict_grade_cart_fit <- 
  predict_grade_cart_workflow %>% 
  fit(data = restaurant_grades_train)

```

### 2. Evaluate the model

```{r}

# use the model to get the predictions on the test data
grade_predictions <- bind_cols(
  restaurant_grades_test,
  predict(object = predict_grade_cart_fit, new_data = restaurant_grades_test)
)

# create a confusion matrix based on predictions of test data
grade_pred_conf_matrix <- table(grade_predictions$.pred_class, grade_predictions$grade)

grade_pred_conf_matrix

# Calculate precision and recall/sensitivity "by hand"
grade_pred_precision <- grade_pred_conf_matrix[1]/(grade_pred_conf_matrix[1] + grade_pred_conf_matrix[3])
grade_pred_precision

grade_pred_recall <- grade_pred_conf_matrix[1]/(grade_pred_conf_matrix[1] + grade_pred_conf_matrix[2])
grade_pred_recall

# Calculate precision and recall/sensitivity with tidymodels
precision(data = grade_predictions, truth = grade, estimate = .pred_class)

recall(data = grade_predictions, truth = grade, estimate = .pred_class)

```
c. The precision and recall calculated "by hand" match the values for precision and recall calculated using the tidymodels functions.

d. The model is very precise, with over 99% precision, meaning that it's almost almost correct when it predicts a restaurant will have an A grade. The model does somewhat worse on recall, with around 81% sensitivity, meaning that when the grade should be an A, there is about a 20% chance the model will predict Not A. In this sense it is a somewhat conservative model: it does not predict an A grade when it shouldn't (false positive), but it occasionally fails to predict A when it should have (false negative). This is probably a good thing for restaurant patrons since it is overly protective of their health, but would harm the marginal restaurant owner who should be receiving an A grade, but is not.

### 3. Improvement

The model is quite precise, but could at least improve its recall (among other metrics) so we would want to make improvements that would ideally reduce false negatives by providing more information to correctly classify restaurants that should've been given an A grade but were not. More information about a restaurant owner's history could be potentially useful: grades from previous years or grades from additional or previous restaurants may be helpful in predicting the current restaurant grade. Additionally, having more specific and descriptive location information (i.e. combining lat/lon to determine relative distance) could help in predicting pockets of restaurants that may receive failing grades because of environmental conditions like the presence of vermin. Experimenting with different algorithms could also be a source of improvement including using a random forest algorithm, which is typically more accurate and still slightly interpretable.

### 4. Variable Importance

```{r}
predict_grade_cart_fit %>% 
  pull_workflow_fit() %>%
  vip(num_features = 10)
```

In CART decision tree models, for each split in the tree the model picks the most efficient predictor or variable to split the data, or the one that reduces misclassification the most/improves the model the most as compared to all other options. Calculating variable importance then requires comparing how often variables are used to perform that split and how relatively valuable that split was in improving the model/reducing error.

For this model, the vast majority of importance comes from the top 3 variables: inspection_type, inspection_date, and census_tract. And of those, inspection_type is by far the most important variable with over twice as much importance as inspection_date and census_tract. Only 7 variables have a non-zero importance with longitude only barely having any relative importance. 

### 5. Application

a. How might this model be used by an ombudsman working for the NYC health department?
This model could be used by the NYC health department to help allocate resources to prioritize health inspections for restaurants that are more likely to have a grade of Not A. It could als 
